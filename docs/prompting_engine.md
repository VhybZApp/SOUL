# SOUL Background Prompting Engine (BPE)

## 1. Purpose

The Background Prompting Engine (BPE) is the crucial component within the SOUL framework that translates the abstract **Internal State** (specifically the Motivation Vector and current Agenda) and assembled **Context** into concrete instructions for the **Pluggable LLM Backend**. Its primary functions are:

*   **Guidance:** Steering the LLM's generation process towards outputs that are Specific, Objective, and aligned with the Soulmade's current Perspective and Agenda.
*   **Abstraction:** Shielding the rest of the SOUL framework from the complexities of direct LLM interaction and prompt engineering nuances for different models.
*   **Control:** Implementing the "Logic" part of SOUL by formulating structured, targeted prompts.

**Design Rationale:** Directly prompting a powerful LLM with only user input often leads to generic or unaligned responses. The BPE introduces a necessary layer of control, leveraging the Soulmade's internal state to guide the LLM effectively, making the interaction purposeful.

## 2. Core Functionality: Generating Background Prompts

The BPE does not generate the final user-facing response directly. Instead, it constructs **Background Prompts** which are sent to the LLM. These prompts are typically invisible to the end-user and contain:

*   **Task Framing:** Instructions setting the context and desired output format.
*   **Motivational Guidance:** Directives derived from the current Motivation Vector (e.g., "Prioritize accuracy," "Adopt a skeptical perspective," "Generate concise action steps").
*   **Contextual Information:** Relevant snippets from conversation history, external knowledge (via [Knowledge Interface](./knowledge_interface.md)), or current Experience state.
*   **Constraints:** Rules or negative constraints (e.g., "Avoid discussing topic X," "Output format must be JSON").

## 3. Guidance from Motivation Framework

The BPE is fundamentally guided by the [Motivation Framework](./motivation_framework.md). The current state of the Motivation Vector influences:

*   **Template Selection:** Choosing appropriate base prompt structures from the `prompt_library/`.
*   **Instruction Injection:** Adding specific clauses or weighting instructions based on active drives (e.g., adding "Be brief" if a "Conciseness" motivation is high).
*   **Refinement Strategy:** Determining whether to ask the LLM for multiple options, a step-by-step breakdown, or a direct answer.

## 4. Seed Templates & `prompt_library/`

The BPE relies on a library of **Seed Prompt Templates** stored in `/prompt_library/` (using Markdown `.md` format).

*   **Purpose:** Provide curated, effective starting points for various tasks and motivational states, derived from best practices and analysis of successful AI interactions.
*   **Content:** Templates include placeholders for context, task specifics, and dynamically injected motivational guidance. They might contain examples, formatting instructions, or role-playing directives for the LLM.
*   **Management:** The `templates.py` module handles loading, selecting, and instantiating these templates.

**Design Rationale:** Using templates with curated seed prompts ensures a baseline level of quality and consistency, leveraging known effective prompting techniques while allowing dynamic adaptation through motivational guidance.

## 5. Template Instantiation & Generation

Based on the current task, context, and motivation state, the BPE:

1.  Selects the most appropriate template(s).
2.  Instantiates the template(s) by filling placeholders with assembled context and motivation-derived instructions.
3.  (Optionally) May generate variations or combine template elements for novel situations, potentially guided by learning mechanisms.

## 6. Refinement Loop & LLM Interaction

For complex tasks, the BPE might engage in a multi-step interaction with the LLM:

*   Sending an initial prompt.
*   Analyzing the LLM's response.
*   Generating follow-up refinement prompts if the initial response is insufficient or needs modification.
*   Synthesizing the final result from multiple LLM interactions.

It uses the abstract [LLM Interface](./#TODO-link-if-llm-interface-doc-exists-or-architecture) (`src/soul/interfaces/llm.py`) to communicate with the chosen backend LLM.

## 7. Evaluation & Learning

The effectiveness of specific background prompts generated by the BPE is tracked (via `components/evaluation/`). This feedback loop allows the framework to learn which prompting strategies are most effective for different situations and motivational states, enabling adaptive refinement over time.
